# ======= TOGGLE =======
# 1 = use LiteLLM proxy, 0 = OpenAI direct
USE_LITELLM="0"


# ============================ LiteLLM proxy path ============================
LITELLM_PROXY_URL="https://litellm-stg.aip.gov.sg"
LITELLM_PROXY_API_KEY="sk--123"

# ---- Model IDs as shown by your /v1/models on LiteLLM ----
LITELLM_MODEL_ID="azure/gpt-5-chat-eastus2"
# LITELLM_MODEL_ID="gemini-2.5-pro"
# LITELLM_MODEL_ID="anthropic.claude-3-5-sonnet-20240620-v1:0"
# LITELLM_MODEL_ID="azure/gpt-4o-mini-eastus"
# LITELLM_MODEL_ID="openai.gpt-oss-120b-1:0"
# LITELLM_MODEL_ID="DeepSeek-R1"
# LITELLM_MODEL_ID="us.meta.llama3-3-70b-instruct-v1:0"




# ============================ OpenAI direct path ============================
OPENAI_API_KEY="sk-456"
OPENAI_MODEL_ID="gpt-4o-mini"